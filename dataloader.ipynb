{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch dataset of for song lyrics\n",
    "class SongData(Dataset):\n",
    "    \n",
    "    # Constructs the dataset by loading in the csv file for song lyrics\n",
    "    def __init__(self, path, csv):\n",
    "        \n",
    "        # Read and preprocess data\n",
    "        self.data = pd.read_csv(os.path.join(path, csv))\n",
    "\n",
    "        # Used for indexing when one-hotting encoding characters\n",
    "        self.encode = self.ChartoOrd(self.data)\n",
    "        # Create the reverse mapping to decode\n",
    "        self.decode = self.OrdtoChar(self.encode)\n",
    "        \n",
    "        # Preprocess data\n",
    "        self.preprocessData(self.data)\n",
    "\n",
    "    # Attach SOS and EOS, uniform text lengths, one-hot all characters\n",
    "    def preprocessData(self, data):\n",
    "        \n",
    "        # Attach SOS, EOS to all text\n",
    "        data['text'] = '\\2' + data['text'] + '\\3'\n",
    "        \n",
    "        # Find maximum length of characters \n",
    "        maxLen = max(data['text'].apply(len))\n",
    "        \n",
    "        # Append EOS to each text until the maxLen is reached\n",
    "        data['text'] = data['text'].apply(lambda x: x + ('\\3' * (maxLen - len(x))))\n",
    "        \n",
    "        # Translate each character into its ordinals once for easy one-hot encoding\n",
    "        data['to_onehot'] = data['text'].apply(lambda x: [self.encode[c] for c in x])\n",
    "        \n",
    "    # Defines length\n",
    "    def __len__(self):\n",
    "        return(len(self.data))\n",
    "    \n",
    "    # Defines how to a single training sample\n",
    "    def __getitem__(self, idx):\n",
    "    \n",
    "        # Get list of ordinal values to transform for this text\n",
    "        indices = self.data.iloc[idx].to_onehot\n",
    "        onehotted = self.onehotted(indices[:-1])\n",
    "        labels = torch.Tensor(indices[1:])\n",
    "        \n",
    "        # One hots the indices and return the tensor\n",
    "        return onehotted, labels.int()\n",
    "    \n",
    "    # Takes a list of indices and create one-hot array for all of these indices\n",
    "    # Return the tensor\n",
    "    def onehotted(self, indices):\n",
    "        \n",
    "        # Dummy array to be indexed\n",
    "        # Row = Character, Column = Possible character\n",
    "        # Size of one-hot is 1xC where C is possible characters\n",
    "        # Size of matrix is NxC where N is the number of characters in this text\n",
    "        dummy = np.zeros((len(indices), len(self.encode)))\n",
    "        \n",
    "        # Index the correct location for each character\n",
    "        dummy[np.arange(len(indices)), indices] = 1\n",
    "        \n",
    "        return torch.Tensor(dummy)\n",
    "    \n",
    "    # Finds all unique characters and assign them an ordinal value \n",
    "    def ChartoOrd(self, data):\n",
    "        \n",
    "        # Dictionary of unique characters\n",
    "        uniqueChars = {}\n",
    "        \n",
    "        # Assign \\2 as SOS and \\3 as EOS mapping the characters to first ordinals\n",
    "        uniqueChars['\\2'] = 0\n",
    "        uniqueChars['\\3'] = 1\n",
    "        \n",
    "        # Ord counter, start at 2 to account for our SOS and EOS\n",
    "        ordCounter = 2\n",
    "        \n",
    "        # Check each character to see if it exists in the dict\n",
    "        # If not give it an ordinal number and increment the ord \n",
    "        # for the next unique character\n",
    "        for lyrics in data.text:\n",
    "            for c in lyrics:\n",
    "                if c not in uniqueChars:\n",
    "                    uniqueChars[c] = ordCounter\n",
    "                    ordCounter += 1\n",
    "            \n",
    "        return uniqueChars\n",
    "    \n",
    "    # Reverse the encoder dict \n",
    "    def OrdtoChar(self, encoder):\n",
    "        \n",
    "        # Make a decoder mapping\n",
    "        decoded = {}\n",
    "        \n",
    "        # Reverse\n",
    "        for k,v in encoder.items():\n",
    "            decoded[v] = k\n",
    "        \n",
    "        \n",
    "        return decoded\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    songSet = SongData('.', 'songdata.csv')\n",
    "\n",
    "    loader = DataLoader(songSet, shuffle=True, batch_size=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 35,  15,  24,  ...,   1,   1,   1],\n",
       "        [  5,   5,  22,  ...,   1,   1,   1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ptorch]",
   "language": "python",
   "name": "conda-env-ptorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
